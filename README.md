# ğŸ“¦ European Public Data Pipeline

A hybrid Azure-based data engineering pipeline for ingesting, validating, transforming, and warehousing European public macroeconomic data from Eurostat (HICP â€“ Harmonised Index of Consumer Prices).

This project demonstrates end-to-end cloud data architecture using Azure Blob Storage and Azure SQL Database.

## ğŸš€ Project Overview

This pipeline ingests official Eurostat macroeconomic data and processes it through a structured multi-layer architecture:

Eurostat API (JSON-stat)
â†’ Azure Blob Storage (Bronze â€“ Raw JSON)
â†’ Azure Blob Storage (Silver â€“ Parquet)
â†’ Data Quality Validation
â†’ Azure SQL Database (Gold â€“ Warehouse Layer)

The pipeline is fully modular, environment-driven, and cloud-ready.

## ğŸ— Architecture

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Eurostat API       â”‚
                 â”‚  (JSON-stat)        â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Azure Blob Storage      â”‚
               â”‚ Bronze (Raw JSON)       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Azure Blob Storage      â”‚
               â”‚ Silver (Parquet)        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Data Quality Layer      â”‚
               â”‚ Validation + Reports    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Azure SQL Database      â”‚
               â”‚ Gold (fact_hicp)        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
## ğŸ§° Tech Stack

Python 3.11+

Pandas

Azure Blob Storage

Azure SQL Database

SQLAlchemy + pyodbc

JSON-stat parsing

Parquet (pyarrow)

Git + GitHub

## ğŸ“‚ Project Structure

```text
european-public-data-pipeline/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ ingestion_hicp_raw.py
â”‚   â”‚   â””â”€â”€ process_hicp_silver.py
â”‚   â”‚
â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â””â”€â”€ check_hicp_quality.py
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ sql.py
â”‚   â”‚   â””â”€â”€ load_hicp_to_sql.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ blob.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ğŸ”„ Pipeline Stages
### 1ï¸âƒ£ Bronze â€” Raw Ingestion

Fetch HICP data from Eurostat and store full JSON-stat payload in Azure Blob Storage.

python -m src.ingestion.ingestion_hicp_raw

Output example:

raw/hicp/prc_hicp_midx/geo=LU/coicop=CP00/ts=20260213_130854.json
### 2ï¸âƒ£ Silver â€” Structured Processing

Parse JSON-stat into a structured Parquet dataset.

python -m src.ingestion.process_hicp_silver

Output schema:

Column	Description
time	Monthly observation date
geo	Country code
coicop	COICOP classification
unit	Index unit (e.g. I15)
value	Inflation index value
processed_at_utc	Processing timestamp
raw_blob	Reference to raw data source
### 3ï¸âƒ£ Data Quality Layer

Validation checks include:

Null value detection

Duplicate primary keys

Numeric value validation

Time continuity

Structural consistency

python -m src.quality.check_hicp_quality

If validation fails, SQL loading is blocked.

### 4ï¸âƒ£ Gold â€” SQL Warehouse Load

Load validated data into Azure SQL:

python -m src.db.load_hicp_to_sql

Target table:

dbo.fact_hicp

This table is optimized for analytical querying and dashboard integration.

## âš™ Configuration

Create a .env file in the root directory:

AZURE_STORAGE_CONNECTION_STRING=
AZURE_BLOB_CONTAINER=eurostat

AZURE_SQL_SERVER=your-server.database.windows.net
AZURE_SQL_DATABASE=europubdata_db
AZURE_SQL_USERNAME=your_admin
AZURE_SQL_PASSWORD=your_password

## ğŸ“Š Current Dataset

Dataset: prc_hicp_midx
Geography: Luxembourg (LU)
COICOP: CP00 (All items)
Frequency: Monthly
Unit: Index (2015 = 100)
